{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8YjwA0hexqT"
   },
   "source": [
    "# üê∂ End-to-end Multi-class Dog Bread Classification\n",
    "\n",
    "This notebook builds an e2e multi-class image classifier using TensorFlow 2.0 and TensorFlow Hub.\n",
    "\n",
    "## 1. Problem\n",
    "Identifying the bread of a dog given an image of a dog.\n",
    "\n",
    "When I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.\n",
    "\n",
    "## 2. Data\n",
    "The data we're using is from Kaggle's [dog breed identification competition](https://www.kaggle.com/competitions/dog-breed-identification/data).\n",
    "\n",
    "## 3. Evaluation\n",
    "The [evaluation](https://www.kaggle.com/competitions/dog-breed-identification/overview/evaluation) is a file with prediction probabilities for each dog breed of each test image.\n",
    "\n",
    "## 4. Features\n",
    "* We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.\n",
    "* There are 120 breeds of dogs (this means there are 120 different classes).\n",
    "* There are around 10,000+ images in the training set (these images have labels)\n",
    "* There are around 10,000+ images in the training set (these images have no labels because we'll want to predict them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pO8LxJ4uCl8S"
   },
   "outputs": [],
   "source": [
    "# Unzip the uploaded data into Google Drive\n",
    "# !unzip \"/drive/MyDrive/Dog Vision/dog-breed-identification.zip\" -d \"/drive/MyDrive/Dog Vision/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGqEVr-9jlhW"
   },
   "source": [
    "### Get our workspace ready\n",
    "\n",
    "* Import TensorFlow 2.x ‚úÖ\n",
    "* Import TensorFlow Hub\n",
    "* Make sure we're using a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NUDMVAAljdZf"
   },
   "outputs": [],
   "source": [
    "# # Import TensorFlow into Colab\n",
    "# import tensorflow as tf\n",
    "# print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7pbIVde1jyw9"
   },
   "outputs": [],
   "source": [
    "# # In case TensorFlow version is less than 2.x\n",
    "# # Import TensorFlow 2.x manually\n",
    "# try:\n",
    "#   # %tensorflow_version only exists in Google Colab\n",
    "#   %tensorflow_version 2.x\n",
    "# except Exception:\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create --prefix .env tensorflow tensorflow-hub jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMNj630yz0MQ",
    "outputId": "69efb022-3e8c-4ad2-b3f8-a3d9984cc45a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.10.0\n",
      "TF Hub version 0.8.0\n",
      "GPU not available :(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary tools\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"TF version\", tf.__version__)\n",
    "print(\"TF Hub version\", hub.__version__)\n",
    "\n",
    "# Check if there's a GPU available\n",
    "print(\"GPU\", \"available (YESSSS!!!!!!)\" \n",
    "      if tf.config.list_physical_devices(\"GPU\") \n",
    "      else \"not available :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g8l6d7_r36zo"
   },
   "outputs": [],
   "source": [
    "# If GPU not available, check if the runtime is set to use a GPU\n",
    "# Runtime > Change runtime type >  Hardware accelerator > GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_k1-HwO4R-R"
   },
   "source": [
    "## Getting our data ready (turning it into Tensors)\n",
    "\n",
    "With all ML models, our data has to be in numerical format. So that's what we'll be doing here, turning our images into Tensors (numerical representations).\n",
    "\n",
    "Let's start by accessing our data and checking out the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEGksrp1HFOz",
    "outputId": "606a2693-fa0d-4088-9723-87e81aaa3393"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dog Vision/dog-breed-identification/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Checkout the labels of our data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m labels_csv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/Dog Vision/dog-breed-identification/labels.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_csv\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_csv\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\complete_ml_ds_bootcamp_2023\\dog-breed-recognition-project\\.env\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dog Vision/dog-breed-identification/labels.csv'"
     ]
    }
   ],
   "source": [
    "# Checkout the labels of our data\n",
    "import pandas as pd\n",
    "\n",
    "labels_csv = pd.read_csv('/content/drive/MyDrive/Dog Vision/dog-breed-identification/labels.csv')\n",
    "print(labels_csv.describe())\n",
    "print(labels_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kjh8I2czHUtR",
    "outputId": "70aa8cf4-ff73-45a4-e75d-099319cbe778"
   },
   "outputs": [],
   "source": [
    "labels_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_u_6FbvKniZ",
    "outputId": "6fed9a37-dd21-4449-b9c1-dc4e618c2c35"
   },
   "outputs": [],
   "source": [
    "labels_csv[\"breed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950
    },
    "id": "3qD39XsaKGaG",
    "outputId": "364bd407-26d7-498a-c154-e727b7d874b8"
   },
   "outputs": [],
   "source": [
    "# How many images are there of each breed?\n",
    "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxVnhFRfKfkB",
    "outputId": "c405137c-bfd1-452d-fa0c-7d32e7307040"
   },
   "outputs": [],
   "source": [
    "labels_csv[\"breed\"].value_counts().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "iMKttYS2Kvfl",
    "outputId": "c6fbb8e4-7c61-4fb2-8289-ae22c111ce8e"
   },
   "outputs": [],
   "source": [
    "# Let's view an image\n",
    "from IPython.display import Image\n",
    "Image(\"/content/drive/MyDrive/Dog Vision/dog-breed-identification/train/\\\n",
    "001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OALLFy8LvXn"
   },
   "source": [
    "### Getting images and their labels\n",
    "\n",
    "Let's get a list of all of our image file pathnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qBWnsnyLMJWm",
    "outputId": "c555c9f2-13a5-47ae-e5e4-86fe38420ad7"
   },
   "outputs": [],
   "source": [
    "labels_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTo1zT_wMCGO",
    "outputId": "884d2567-abaf-4422-a326-b2ebc84356ca"
   },
   "outputs": [],
   "source": [
    "# Create pathnames from image IDs - part 1\n",
    "filenames = [fname for fname in labels_csv[\"id\"]]\n",
    "\n",
    "# Check the first 5\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TthVr0TUMTyr",
    "outputId": "25d548e9-ade6-432e-cc55-ff2369d75e51"
   },
   "outputs": [],
   "source": [
    "# Create pathnames from image IDs - part 2\n",
    "filenames = [\"/content/drive/MyDrive/Dog Vision/dog-breed-identification/train/\"\\\n",
    "             + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
    "\n",
    "# Check the first 5\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xTg8CmCMl4f",
    "outputId": "e0eba32f-45b0-4575-890a-287c5723f023"
   },
   "outputs": [],
   "source": [
    "# Check whether number of filenames matches number of actual image files\n",
    "import os\n",
    "if len(os.listdir(\"/content/drive/MyDrive/Dog Vision/dog-breed-identification/train/\")) == len(filenames):\n",
    "  print(\"Filenames match actual amount of files in our ../train/ folder!\\nProceed with TF! ^_^\")\n",
    "else:\n",
    "  print(\"Filenames do not match actual amount of files, check the target directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "s_DpOFxyNwas",
    "outputId": "f310f749-abba-4c61-e732-3c2eaebee25f"
   },
   "outputs": [],
   "source": [
    "# One more check\n",
    "Image(filenames[9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J1I8Zpq9OmF-",
    "outputId": "40a9c472-ac1a-42f3-95ab-efe89c089a83"
   },
   "outputs": [],
   "source": [
    "labels_csv[\"breed\"][9000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVMLPMQOU-5g"
   },
   "source": [
    "Since we've now got our training image filepaths in a list, let's prepare our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVKeTO55VGcz",
    "outputId": "638d2172-6985-4e84-8cc3-25b27f8f42de"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = labels_csv[\"breed\"]\n",
    "labels = np.array(labels)\n",
    "# labels = labels_csv[\"breed\"].to_numpy() # does same thing as above\n",
    "labels, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtR187k7VLve",
    "outputId": "007765a4-b95e-42db-d992-7035c8765745"
   },
   "outputs": [],
   "source": [
    "# See if number of labels matches number of filenames\n",
    "if len(labels) == len(filenames):\n",
    "  print(\"Number of labels matches number of filenames!\")\n",
    "else:\n",
    "  print(\"Number of labels does not match number of filenames, check data directories!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Dr4lOHsV_to",
    "outputId": "38416b78-f702-43fe-d390-c3ae43fd6624"
   },
   "outputs": [],
   "source": [
    " # Find the unique label values\n",
    " unique_breeds = np.unique(labels)\n",
    " len(unique_breeds), unique_breeds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwShiaHmW2Lf",
    "outputId": "c15b8949-42b1-403f-beda-943498108e05"
   },
   "outputs": [],
   "source": [
    "# Turn a single label into an array of booleans\n",
    "print(labels[0])\n",
    "labels[0] == unique_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYF_Ghf3XbeJ",
    "outputId": "579c8077-f66d-4851-f3b6-70ac40bc4bfa"
   },
   "outputs": [],
   "source": [
    "# Turn every label into a boolean array\n",
    "boolean_labels = [label == unique_breeds for label in labels]\n",
    "boolean_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UH1WJlXBX7c3",
    "outputId": "26c763e4-d182-4b10-e007-dd9f86a4f377"
   },
   "outputs": [],
   "source": [
    "len(boolean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th4zJDEAYBM5",
    "outputId": "6d925843-ea88-41bb-f9ef-3e10147a97ff"
   },
   "outputs": [],
   "source": [
    "# Example: turning boolean array into integers\n",
    "print(labels[0]) # original label\n",
    "print(np.where(unique_breeds == labels[0])) # index where label occurs\n",
    "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
    "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlaGYH2EYiV0"
   },
   "source": [
    "### Creating our own validation set\n",
    "\n",
    "Since the dataset from Kaggle doesn't come with a validation set, we're going to create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_WVdgvDZUFx"
   },
   "outputs": [],
   "source": [
    "# Setup X & y variables\n",
    "X = filenames\n",
    "y = boolean_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzepVzWzZnzh",
    "outputId": "b3022cc9-8a40-4a56-e040-17f00af7dcd6"
   },
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfnBZ_dgZtPX"
   },
   "source": [
    "We're going to start off experimenting with ~1000 images and increase as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UE9W6aEZ-f3"
   },
   "outputs": [],
   "source": [
    "# Set number of images to use for experimenting\n",
    "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qU4XoZ2KaSZq",
    "outputId": "61e7c1cc-64fb-4abc-c1b7-a087d4c12e9c"
   },
   "outputs": [],
   "source": [
    "# Let's split our data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and validation of total size NUM_IMAGES\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
    "                                                  y[:NUM_IMAGES],\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Check our train and validation sets' length\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsINHDRka4ZN",
    "outputId": "f34dec77-74c9-449c-8b74-10b7fb80afd6"
   },
   "outputs": [],
   "source": [
    "# Let's have a geez at the training data\n",
    "X_train[:5], y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIYnvSrsbKJ2"
   },
   "source": [
    "## Preprocessing Images (Turning Images into Tensors)\n",
    "\n",
    "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
    "1. Take an image filepath as input\n",
    "2. Use TensorFlow to read the file and save it to a variable, e.g. `image`\n",
    "3. Turn our `image` (a jpg) into Tensors\n",
    "4. Normalize our `image` (convert colour channel values from 0-255 to 0-1).\n",
    "5. Resize the `image` to be a shape of (224, 224)\n",
    "6. Return the modified `image`\n",
    "\n",
    "TensorFlow documentation on loading data:\n",
    "* [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n",
    "* [Load and preprocess images](https://www.tensorflow.org/tutorials/load_data/images)\n",
    "\n",
    "Before we do, let's see what importing an image looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np55RWK9buaA",
    "outputId": "da167f3e-cd43-4e3d-aa70-d51617706b68"
   },
   "outputs": [],
   "source": [
    "# Convert an image to a NumPy array\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "image = imread(filenames[42])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYvwCeG9dfUa",
    "outputId": "0d46a229-8c39-425c-b454-f9e01f02f6ea"
   },
   "outputs": [],
   "source": [
    "image[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bzd0XzO2drNb",
    "outputId": "154e5b61-54da-460c-b009-f1a4fc0ae79b"
   },
   "outputs": [],
   "source": [
    "# each image is composed of pixels made up of RGB color values between 0 and 255\n",
    "image.min(), image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRAj6PlMdzmo",
    "outputId": "8d30ebc6-7545-47fc-a349-1d125fe8e05b"
   },
   "outputs": [],
   "source": [
    "# turn that same image into a Tensor that can be run on a GPU\n",
    "tf.constant(image)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epAXH2mMeQKS"
   },
   "source": [
    "Now we've seen what an image looks like as a Tensor, let's make a function to preprocess them.\n",
    "1. Take an image filepath as input\n",
    "2. Use TensorFlow to read the file and save it to a variable, e.g. `image`\n",
    "3. Turn our `image` (a jpg) into Tensors\n",
    "4. Normalize our `image` (convert colour channel values from 0-255 to 0-1).\n",
    "5. Resize the `image` to be a shape of (224, 224)\n",
    "6. Return the modified `image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKi7MhxvkqMg"
   },
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Create a function for preprocessing images\n",
    "def process_image(image_path, img_size=IMG_SIZE):\n",
    "  \"\"\"\n",
    "  Takes an image file path and image size as inputs and turns\n",
    "  the image into a Tensor.\n",
    "  \"\"\"\n",
    "  # Read an image file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  # Turn the jpeg image into numerical Tensor with 3 colour channels (RGB)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  # Convert the colour channel values from 0-255 to 0-1 values (normalization)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  # Resize the image to our desired value (224, 224)\n",
    "  image = tf.image.resize(image, size=[img_size, img_size])\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8n4XlJfYpmLM"
   },
   "outputs": [],
   "source": [
    "# Break down the process_image function line-by-line to see what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuV4fKPvl0fn"
   },
   "outputs": [],
   "source": [
    "# # Check the contents of one Tensor\n",
    "# tensor = tf.io.read_file(filenames[26])\n",
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahLhjjZXl5zS"
   },
   "outputs": [],
   "source": [
    "# # Check the output of decoding one Tensor\n",
    "# tensor = tf.image.decode_jpeg(tensor, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgrERLexm6OQ"
   },
   "outputs": [],
   "source": [
    "# # Normalization\n",
    "# # Check the output of a decoded tensor converted from 0-255 to 0-1 values\n",
    "# tf.image.convert_image_dtype(tensor, tf.float32)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFf73LnnnwBX"
   },
   "source": [
    "`Yann Lecun`, a renowned computer scientist and AI researcher, tweeted in April 2018 that \"Friends don‚Äôt let friends use mini-batches larger than `32`\" ¬π. However, in May 2021, he tweeted that the optimal batch size is `128` ¬≥. \n",
    "\n",
    "In general, the optimal batch size will be lower than 32 ¬π. However, there is no magic batch size number that works for all cases as it depends on the complexity of your data and the GPU constraints you have ‚Åµ. \n",
    "\n",
    "I hope this helps! Let me know if you have any other questions.\n",
    "\n",
    "Source: Conversation with Bing, 4/5/2023\n",
    "1. Neural Networks - How do I choose the optimal batch size? - Artificial .... https://bing.com/search?q=yann+lecun+optimal+batch+size.\n",
    "2. Yann LeCun on Twitter: \"No contrastive samples, no huge batch size .... https://twitter.com/ylecun/status/1391164045902888967.\n",
    "3. How to get 4x speedup and better generalization using the right batch size. https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf.\n",
    "4. Neural Networks - How do I choose the optimal batch size? - Artificial .... https://ai.stackexchange.com/questions/8560/how-do-i-choose-the-optimal-batch-size.\n",
    "5. Training Nets with Large Batch Size - GitHub Pages. https://samliu.github.io/2019/03/11/large-batch-sizes.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-yrie-2Jw4B"
   },
   "source": [
    "## Turning Our Data into Batches\n",
    "\n",
    "Why turn our data into batches?\n",
    "\n",
    "Let's say you're trying to process 10k+ images in one go, they all might not fit into memory (e.g., 16GB RAM, 8GB VRAM). That's why we do about 32 images at a time (batch size).\n",
    "\n",
    "In order to use TensorFlow effectively, we need our data in the form of Tensor tuples which look like this: `(image, label)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eqCvk90KSjp"
   },
   "outputs": [],
   "source": [
    "# Create a simple function to return a tuple (image, label) of Tensors\n",
    "def get_image_label(image_path, label):\n",
    "  \"\"\"\n",
    "  Takes an image file path name and the associated label,\n",
    "  processes the image and returns a tuple of (image, label).\n",
    "  \"\"\" \n",
    "  \n",
    "  return process_image(image_path), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V1XN-0FLi2i"
   },
   "outputs": [],
   "source": [
    "# # Demo of the above function - tuple of (image, label) pair in the form of Tensors\n",
    "# (process_image(X[42]), tf.constant(y[42]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmZ7HzlZLsyS"
   },
   "source": [
    "Now we've got a way to turn our data into tuples of Tensors in the form: \n",
    "`(image, label)`, let's make a function to turn all of our data (`X` & `y`)\n",
    "into batches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKE0KicHNtvg"
   },
   "outputs": [],
   "source": [
    "# Define the batch size, 32 is a good start\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a function to turn data into batches\n",
    "def create_data_batches(X, y=None, batch_size=BATCH_SIZE, \n",
    "                        valid_data=False, test_data=False):\n",
    "  \"\"\"\n",
    "  Creates batches of data out of image (X) and label (y) pairs.             \n",
    "  It shuffles the data if it's training data, but doesn't shuffle if it's \n",
    "  validation data. Also accepts test data as input (no labels).\n",
    "  \"\"\"\n",
    "  # If the data is a test dataset, we don't have labels\n",
    "  if test_data:\n",
    "    print(\"Creating test data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths\n",
    "    data_batch = data.map(process_image).batch(BATCH_SIZE) # only filepaths\n",
    "    return data_batch\n",
    "\n",
    "  # If the data is a valid dataset, we don't need to shuffle it\n",
    "  elif valid_data:\n",
    "    print(\"Creating validation data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n",
    "                                               tf.constant(y))) # labels\n",
    "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "\n",
    "  # If not a test or valid dataset, then it's a training batch\n",
    "  else:\n",
    "    print(\"Creating training data batches...\")\n",
    "    # Turn filepaths and labels into Tensors\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
    "                                               tf.constant(y)))\n",
    "    # Shuffling filenames and labels before mapping image processor function \\\n",
    "    # is faster than shuffling images\n",
    "    data = data.shuffle(buffer_size=len(X)) # shuffle the whole lot (len(X))\n",
    "    \n",
    "    # Create (image, label) tuples \\\n",
    "    # This also turns the image path into a preprocessed image\n",
    "    data = data.map(get_image_label)\n",
    "\n",
    "    # Turn the training data into batches\n",
    "    data_batch = data.batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gia2PQSiQF0T",
    "outputId": "7d61dcb3-0ffe-474a-d8f2-31eed50dace2"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "# Create training and validation data batches \\\n",
    "# Test our create_data_batches function\n",
    "train_data = create_data_batches(X_train, y_train)\n",
    "val_data = create_data_batches(X_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whvQVGUuSyA9",
    "outputId": "347767af-86a7-445a-846e-5b01359fd6c8"
   },
   "outputs": [],
   "source": [
    "# Check out the different attributes of our data batches\n",
    "train_data.element_spec, val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uGqd007TO5b"
   },
   "source": [
    "## Visualizing Data Batches\n",
    "\n",
    "Our data is now in batches, however these can be a little hard to understand,\n",
    "let's visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J_OBOlZ5dFK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a function for viewing images in a data batch\n",
    "def show_25_images(images, labels):\n",
    "  \"\"\"\n",
    "  Displays a plot of 25 images and their labels from a data batch.\n",
    "  \"\"\"\n",
    "  # Setup the figure\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  #Loop through 25 (for displaying 25 images)\n",
    "  for i in range(25):\n",
    "    # Create subplots (5 rows, 5 columns)\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    # Display an image\n",
    "    plt.imshow(images[i])\n",
    "    # Add the image label as the title\n",
    "    plt.title(unique_breeds[labels[i].argmax()])\n",
    "    # Turn the grid lines off\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_jXvPEn7q5c"
   },
   "source": [
    "`.argmax()` is a method in Python that returns the indices of the maximum values along an axis. It is used to get the index of the maximum value in an array. Here's an example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 2, 1])\n",
    "print(np.argmax(a))\n",
    "```\n",
    "\n",
    "This will output `2`, which is the index of the maximum value in array `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUZBx7Ac6EOE",
    "outputId": "b7066c0a-5ae9-4a85-f9fb-8967bdc713b2"
   },
   "outputs": [],
   "source": [
    "# The indices 19 has the maximum value in our y array, that is the value True (1)\n",
    "y[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uSIG6An57KsN",
    "outputId": "a728a7f2-af28-4498-ebec-cfb98bc382e4"
   },
   "outputs": [],
   "source": [
    "unique_breeds[y[0].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yLTymw76eXE",
    "outputId": "01f9ead1-5b40-49ca-af4f-e74cd918f23d"
   },
   "outputs": [],
   "source": [
    "unique_breeds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ir2i8d7X8dZJ",
    "outputId": "7d27d49c-02f4-45a6-ddfe-51294026fbb3"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcBbrcPd6qlm"
   },
   "outputs": [],
   "source": [
    "# Split our batch train_data into train_images and train_labels == un-batch it\n",
    "train_images, train_labels = next(train_data.as_numpy_iterator()) # returns the next item from an iterator\n",
    "# train_images[:5], train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFCJoNOm8PiB",
    "outputId": "e6890108-0c0f-4563-994e-dad378d41e3e"
   },
   "outputs": [],
   "source": [
    "len(train_images), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "pigPdMkx9YMJ",
    "outputId": "0d127884-b19d-4318-a4c0-7facdb27e53f"
   },
   "outputs": [],
   "source": [
    "# Now let's visualize the data in a training batch\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "so3dXt4q9rRW",
    "outputId": "d954bf42-0ef2-4bdd-b505-01f6e1cfa056"
   },
   "outputs": [],
   "source": [
    "# Now let's visualize our validation set\n",
    "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
    "show_25_images(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9O3nK5VIO5wm"
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # Open an image file\n",
    "# with Image.open(\"/content/drive/MyDrive/Dog Vision/tensor-flow.png\") as im:\n",
    "#     # Display image\n",
    "#     im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3P5qxDtSbGt"
   },
   "source": [
    "## Building a Model\n",
    "\n",
    "Before we build a model, there are a few things we need to define:\n",
    "* The input shape (our image's shape, in the form of Tensors) of our model.\n",
    "* The output shape (image labels, in the form of Tensors) of our model.\n",
    "* The URL of th emodel we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "0sFy46kwSFtc",
    "outputId": "67d39f0b-4838-46f9-bcd6-beef70e64c42"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/content/drive/MyDrive/Dog Vision/tensor-flow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "_kN673YZTJGH",
    "outputId": "7a280708-77a8-4fd1-b57a-a2130c48e391"
   },
   "outputs": [],
   "source": [
    "Image(\"/content/drive/MyDrive/Dog Vision/tensor-flow_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbA0TZLSTLVE"
   },
   "outputs": [],
   "source": [
    "# Setup input shape to the model\n",
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
    "\n",
    "# Setup output shape of our model\n",
    "OUTPUT_SHAPE = len(unique_breeds)\n",
    "\n",
    "# Setup model URL from TensorFlow Hub\n",
    "MODEL_URL = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJNtHexkU2Dn"
   },
   "source": [
    "## **Optional: How machines learn and what's going on behind the scenes?**\n",
    "\n",
    "<div data-purpose=\"safely-set-inner-html:rich-text-viewer:html\" class=\"article-asset--content--1dAQ9 rt-scaffolding\"><p>Massive effort getting the data ready for use with a machine learning model! This is one of the most important steps in any machine learning project.</p><p>Now you've got the data ready, you're about to dive headfirst into writing deep learning code with TensorFlow 2.x.</p><p>Since we're focused on writing code first and foremost, these videos are optional but they're here for those who want to start to get an understanding of what goes on behind the scenes.</p><p><strong>How Machines Learn</strong></p><p>The first is a video called <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.youtube.com/watch?v=R9OHn5ZF4Uo\">How Machines Learn by GCP Grey on YouTube</a>.</p><p>It's a non-technical narrative explaining how some of the biggest tech companies in the world use data to improve their businesses. In short, they're leveraging techniques like the ones you've been learning. Instead of trying to think of every possible rule to code, they collect data and then use machines to figure out the patterns for them.</p><p><strong>What actually is a neural network?</strong></p><p>You're going to be writing code which builds a neural network (a type of machine learning model) so you might start to wonder, what's going on when you run the code?</p><p>When you pass inputs (often data and labels) to a neural network and it figures out patterns between them, how is it doing so?</p><p>When it tries to make predictions and gets them wrong, how does it improve itself?</p><p>The <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.youtube.com/watch?v=aircAruvnKk\">deep learning series by 3Blue1Brown on YouTube</a> contains a technical deep-dive into what's going on behind the code you're writing.</p><p>Be warned though, it isn't for the faint of heart. The videos explain the topics in a beautiful way but it doesn't mean the topics aren't still difficult to comprehend.</p><p>If you're up for it, a good idea would be to watch 1 video in the series one day and then another the day after and so on.</p><p>Remember, you don't need to know all of these things to get started writing machine learning code. Focus on solving problems first (like we're doing in this project) and then dive deeper when you need to.</p><p>And since these videos are optional, feel free to bookmark them for now, continue with the course and come back later!</p><p>Links:</p><p>(Non-technical) How Machines Learn by GCP Grey: <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.youtube.com/watch?v=R9OHn5ZF4Uo\">https://www.youtube.com/watch?v=R9OHn5ZF4Uo</a></p><p>(Technical) Deep Learning series by 3Blue1Brown: <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.youtube.com/watch?v=aircAruvnKk\">https://www.youtube.com/watch?v=aircAruvnKk</a></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tub1AVyhVLmo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
